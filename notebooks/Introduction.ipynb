{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "from numpy import linalg\n",
    "import math\n",
    "# import cProfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit my github, https://github.com/gary-dalton/math793"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to solve a system of linear equations using Cramer's rule instead of using the current standard methods.\n",
    "\n",
    "We will consider linear equations in the form of $Ax=b$, where $A$ is a non-singular $n\\times n$ matrix, $b$ is a $n\\times 1$ unknown vector, and $b$ is a given $n\\times 1$ vector. Cramer's rules states that\n",
    "\\begin{align*}\n",
    "\tx_i = \\frac{\\det(A_i(b))}{\\det(A)}, i=1,2,\\cdots,n\n",
    "\\end{align*}\n",
    "where $A_i(b)$ denotes the matrix $A$ with its ith column replaced by $b$.\n",
    "\n",
    "The standard method of computing the determinant by recursion of minors is not an efficient computation algorithm. In fact, its complexity is of $O(N!)$, which makes it useless for real world problems. Instead, methods are used to row reduce the matrix to obtain upper and lower triangular matrices and then compute the determinate from those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following system of equations:\n",
    "\\begin{align*}\n",
    "\ta_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 \\\\\n",
    "\ta_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 \\\\\n",
    "\ta_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3\n",
    "\\end{align*}\n",
    "With\n",
    "\\begin{align*}\n",
    "\t&A = \\begin{bmatrix}\n",
    "\t\ta_{1,1} & a_{1,2} & a_{1,3} \\\\\n",
    "\t\ta_{2,1} & a_{2,2} & a_{2,3} \\\\\n",
    "\t\ta_{3,1} & a_{3,2} & a_{3,3}\n",
    "\t\\end{bmatrix}, &\n",
    "\t&x = \\begin{bmatrix}x_1 \\\\\tx_2 \\\\\tx_3\t\\end{bmatrix}, & \n",
    "\tb = \\begin{bmatrix} b_1 \\\\\tb_2 \\\\\tb_3\t\\end{bmatrix}&\n",
    "\\end{align*}\n",
    "Then\n",
    "\\begin{align*}\n",
    "\tx_1 &= \\frac{\\det\\begin{bmatrix}\n",
    "\t\t\tb_1 & a_{1,2} & a_{1,3} \\\\\n",
    "\t\t\tb_2 & a_{2,2} & a_{2,3} \\\\\n",
    "\t\t\tb_3 & a_{3,2} & a_{3,3}\n",
    "\t\t\\end{bmatrix}\n",
    "\t}{\\det(A)}, &\n",
    "\tx_2 = \\frac{\\det\\begin{bmatrix}\n",
    "\t\t\ta_{1,1} & b_1 & a_{1,3} \\\\\n",
    "\t\t\ta_{2,1} & b_2 & a_{2,3} \\\\\n",
    "\t\t\ta_{3,1} & b_3 & a_{3,3}\n",
    "\t\t\\end{bmatrix}\n",
    "\t}{\\det(A)}, & &\n",
    "\tx_3 = \\frac{\\det\\begin{bmatrix}\n",
    "\t\t\ta_{1,1} & a_{1,2} & b_1 \\\\\n",
    "\t\t\ta_{2,1} & a_{2,2} & b_2 \\\\\n",
    "\t\t\ta_{3,1} & a_{3,2} & b_3\n",
    "\t\t\\end{bmatrix}\n",
    "\t}{\\det(A)}&\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current technology with python to solve a system of linear equations uses *scipy.linalg.solve*. This in turn uses routines from LAPACK, \"The generic, symmetric, Hermitian and positive definite solutions are obtained via calling ?GESV, ?SYSV, ?HESV, and ?POSV routines of LAPACK respectively.\"\n",
    "\n",
    "There are specialized solutions for known special matrices, but we are most interested in the generic solver. From the documentation of ?GESV, we have, \n",
    "\n",
    "> ?GESV computes the solution to a real system of linear equations\n",
    "> \\begin{align*} \tA * X = B \\end{align*}\n",
    "> where A is an N-by-N matrix and X and B are N-by-NRHS matrices.\n",
    ">\n",
    "> The LU decomposition with partial pivoting and row interchanges is used to factor A as\n",
    "> \\begin{align*}A = P * L * U\\end{align*}\n",
    "> where P is a permutation matrix, L is unit lower triangular, and U is upper triangular.  The factored form of A is then used to solve the system of equations $A * X = B$.\n",
    "\n",
    "The complexity of the ?GESV algorithm is indicated as $O(.67N^3)$. This is obtained from table 3.13 in https://www.netlib.org/lapack/lug/node71.html.\n",
    "\n",
    "**Note:** The relationship between Scipy and Numpy is close. Generally the functions are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to System of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soltuion to a system of equations is found using forward and backward substitution.\n",
    "\\begin{align*}\n",
    "\tAx &= b \\\\\n",
    "    LUx &= b \\\\\n",
    "    Ly &= b \\\\\n",
    "    Ux &=y\n",
    "\\end{align*}\n",
    "Where $Ly=b$ is solved using forward substitution and $Ux=y$ is solved using backward substitution. The great advantage of this approach is that the LU decompistion and forward substituion are performed once to find all of the solutions. This adds a complexity to the algoritm of no more than $O(n^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinants of triangular matrices are easily calculated as the product of the diagonal entries. Thus $\\det(L) =1$ and $\\det(U)$ is easily calculated by $O(n)$ operations. Since P is a permutation matrix, its determinant is trivial to calculate using the method of minors and is of order $O(n)$. $det(P)$ equals either $1$ or $-1$. So that we have:\n",
    "\\begin{align*}\n",
    "\t\\det(A) = \\det(P) * \\det(U)\n",
    "\\end{align*}\n",
    "This is the method used by both numpy and scipy to calculate a determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cramer's Rule and LU Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above discussion, Cramer's Rule could be used to solve systems of equations by calculating the various determinants using LU decomposition as an intermediate step. This would give us computation complexity on the order of $O(.67N^3)$ for LU Decomposition $\\times$ $O(n)$ for the number of variables to solve. With the result of at best $O(.67N^4)$. This is due to the need to perform LU Decomposition for each $A_i(b)$. If there were a method to reduce this need we might have a competitive algorithm computationally.\n",
    "\n",
    "I did find one approach that does claim to reduce this complexity to about $O(N^3)$. This is from the Journal of Discrete Algorithms, http://web.eecs.utk.edu/~ielhanan/Papers/JDA2011.pdf, and it uses Chio's condensation method and a few other tricks. I am not certain of this algorithm yet. However, even using this approach does not reduce the overall complexity of solving the system of equations. Instead, there would need to be other benefits, such as better stability or higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test matrices are an important part of validating algorithms, both for computation speed and accuracy. There are many matrices available for direct download from https://math.nist.gov/MatrixMarket/index.html. These may be downloaded in MatrixMarket format and then pulled into the test program with the following code snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 480, 17088, 'coordinate', 'real', 'general')\n"
     ]
    }
   ],
   "source": [
    "from scipy import io\n",
    "print(io.mminfo('rbs480a.mtx'))\n",
    "a = io.mmread('rbs480a.mtx')\n",
    "A=  a.todense()\n",
    "n = len(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, many test matrices are generated. Often, these were generated using The Matrix Computation Toolkit for Matlab. A very useful python package to generate a variety of test matrices is in Scipy.sparse. See the code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCUMENTATION: https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "# https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "import scipy.sparse as sparse\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[20., 29., 29.,  0., 29.],\n",
       "        [23.,  0., 26.,  0., 30.],\n",
       "        [28., 30., 30., 29., 31.],\n",
       "        [ 0., 23., 25., 34., 25.],\n",
       "        [29.,  0.,  0., 24., 26.]]),\n",
       " matrix([[ 0.        ,  0.        , 12.49613651],\n",
       "         [ 0.        ,  0.        ,  0.        ],\n",
       "         [23.13238941, 55.20213547,  7.8567203 ]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sets reproducibility\n",
    "np.random.seed(5) \n",
    "# Poisson\n",
    "rvs = stats.poisson(18, loc=10).rvs\n",
    "# generate sparse 5x5 random matrix with density 0.75\n",
    "A = sparse.random(5, 5, density=0.75, data_rvs=rvs)\n",
    "rvs = stats.norm(loc=10, scale=20).rvs\n",
    "# create sparse 3x3 matrix with density 0.5\n",
    "B = sparse.random(3, 3, density=0.50, data_rvs=rvs)\n",
    "A = A.toarray()\n",
    "B = B.todense()\n",
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a difference in using either of these forms, matrix or array? I think that either will work fine but numpy is most suitable for working with arrays for slicing and dicing. So mostly, this work will use the array form of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve a linear system by Cramer's formula\n",
    "Consider the **linear systems** in the matrix form $Ax = b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Function for Cramer's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramer_solve(A, b):\n",
    "    \"\"\"Solve a system of linear equations using Cramer's Rule and LU Decomposition.\n",
    "    Returns the solution vector.\"\"\"\n",
    "    \n",
    "    # LU Decomposition\n",
    "    p,l,u = sla.lu(A)\n",
    "    DA = sla.det(p)*sla.det(u)\n",
    "    \n",
    "    # Solution storage\n",
    "    x = np.zeros((n,1))\n",
    "    x.astype(double)\n",
    "    \n",
    "    # Loop to find each solution\n",
    "    for i in range(len(b)):\n",
    "        Ai = np.copy(A)\n",
    "#         print(np.shape(Ai), np.shape(b))\n",
    "        Ai[:,i] = b[:,0]\n",
    "        p,l,u = sla.lu(Ai)\n",
    "        DAi = sla.det(p)*sla.det(u)\n",
    "        x[i] = DAi / DA\n",
    "#         print(x[i])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cramer_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a run and create test matrices\n",
    "import scipy.sparse as sparse\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as sla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test matrices\n",
    "# Enter a value of n\n",
    "n=100\n",
    "# Sets reproducibility\n",
    "np.random.seed(3) \n",
    "# Use Poisson\n",
    "rvs = stats.poisson(18, loc=10).rvs\n",
    "# Generate test matrices A and b\n",
    "A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate total absolute error compared to built-in solver\n",
      "1.333072541243041e-12\n"
     ]
    }
   ],
   "source": [
    "# cramer_solve\n",
    "x = cramer_solve(A,b)\n",
    "\n",
    "# numpy solve\n",
    "y=linalg.solve(A,b)\n",
    "\n",
    "print (\"Approximate total absolute error compared to built-in solver\")\n",
    "print(sum(abs(x-y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems\n",
    "\n",
    "* The determinant calculations can overflow the data type\n",
    "* Some conditioning will be needed to prevent overflow\n",
    "* Duplication of some calculations\n",
    "* This is not an optimized algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preventing Overflow / Underflow\n",
    "Try using linalg.slogdet instead of linalg.det.\n",
    "> Compute the sign and (natural) logarithm of the determinant of an array.\n",
    ">\n",
    "> If an array has a very small or very large determinant, then a call to det may overflow or underflow. This routine is more robust against such issues, because it computes the logarithm of the determinant rather than the determinant itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified cramer_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramer_solve_slog(A, b):\n",
    "    \"\"\"Solve a system of linear equations using Cramer's Rule and LU Decomposition.\n",
    "    Returns the solution vector.\"\"\"\n",
    "    \n",
    "    # LU Decomposition\n",
    "    p,l,u = sla.lu(A)\n",
    "    DA_sign, DA_logdet = gd_det(p,u)\n",
    "    \n",
    "    # Solution storage\n",
    "    x = np.zeros((n,1))\n",
    "    x.astype(double)\n",
    "    \n",
    "    # Loop to find each solution\n",
    "    for i in range(len(b)):\n",
    "        Ai = np.copy(A)\n",
    "#         print(np.shape(Ai), np.shape(b))\n",
    "        Ai[:,i] = b[:,0]\n",
    "        p,l,u = sla.lu(Ai)\n",
    "        DAi_sign, DAi_logdet = gd_det(p,u)\n",
    "        x[i] = DA_sign * DAi_sign * np.exp(DAi_logdet - DA_logdet)\n",
    "#         print(x[i])\n",
    "    return x\n",
    "\n",
    "def gd_det(*args):\n",
    "    tsign = 1\n",
    "    tlogdet= 0\n",
    "    for arg in args:\n",
    "        sign, logdet = linalg.slogdet(arg)\n",
    "        tsign = tsign * sign\n",
    "        tlogdet = tlogdet + logdet\n",
    "    return tsign, tlogdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test matrices\n",
    "# Enter a value of n\n",
    "n=800\n",
    "# Sets reproducibility\n",
    "np.random.seed(3) \n",
    "# Use Poisson\n",
    "rvs = stats.poisson(18, loc=10).rvs\n",
    "# Generate test matrices A and b\n",
    "A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate total absolute error compared to built-in solver\n",
      "5.929695047479644e-09\n"
     ]
    }
   ],
   "source": [
    "# cramer_solve\n",
    "x = cramer_solve_slog(A,b)\n",
    "\n",
    "# numpy solve\n",
    "y=linalg.solve(A,b)\n",
    "\n",
    "print (\"Approximate total absolute error compared to built-in solver\")\n",
    "print(sum(abs(x-y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard cramer_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time for Cramer_solve = 1.03275 seconds\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b by Cramer formulas\n",
    "t0 = time.time()\n",
    "# Set iterations and matrix size\n",
    "i=100\n",
    "for n in range(10, 10+i):\n",
    "    np.random.seed(n) \n",
    "    rvs = stats.poisson(18, loc=10).rvs\n",
    "    A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "    b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()\n",
    "    x = cramer_solve(A,b)\n",
    "t1 = time.time() \n",
    "cramer_time = t1 - t0\n",
    "print('CPU time for Cramer_solve = %g seconds'%(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time for Linalg_solve = 0.100022 seconds\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b by built-in methods\n",
    "t0 = time.time()\n",
    "# Set iterations and matrix size\n",
    "i=100\n",
    "for n in range(10, 10+i):\n",
    "    np.random.seed(n) \n",
    "    rvs = stats.poisson(18, loc=10).rvs\n",
    "    A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "    b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()\n",
    "    x = linalg.solve(A,b)\n",
    "t1 = time.time() \n",
    "linalg_time = t1 - t0\n",
    "print('CPU time for Linalg_solve = %g seconds'%(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified cramer_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time for Cramer_solve = 175.409 seconds\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b by Cramer formulas\n",
    "accumulated_time = 0\n",
    "# Set iterations and matrix size\n",
    "i=1000\n",
    "for n in range(i-5, i):\n",
    "    np.random.seed(n) \n",
    "    rvs = stats.poisson(18, loc=10).rvs\n",
    "    A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "    b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()\n",
    "    t0 = time.time()\n",
    "    x = cramer_solve(A,b)\n",
    "    t1 = time.time() \n",
    "    accumulated_time += (t1-t0)\n",
    "print('CPU time for Cramer_solve = %g seconds'%(accumulated_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU time for Cramer_solve = 0.0370092 seconds\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b by built-in methods\n",
    "accumulated_time = 0\n",
    "# Set iterations and matrix size\n",
    "i=1000\n",
    "for n in range(i-5, i):\n",
    "    np.random.seed(n) \n",
    "    rvs = stats.poisson(18, loc=10).rvs\n",
    "    A = sparse.random(n, n, density=0.75, data_rvs=rvs).toarray()\n",
    "    b = sparse.random(n, 1, density=0.9, data_rvs=rvs).toarray()\n",
    "    t0 = time.time()\n",
    "    x = linalg.solve(A,b)\n",
    "    t1 = time.time() \n",
    "    accumulated_time += (t1-t0)\n",
    "print('CPU time for Cramer_solve = %g seconds'%(accumulated_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.876638650894165"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "395*5* accumulated_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts, Opinions, and Future Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hold the opinion that attempting a more efficient general system of equations solver is not a good use of time. Instead, there may be some interesting and large areas of study that involve sparse matrices or specialized solutions. Potential matrices of this type are available through _NLEVP: A Collection of Nonlinear Eigenvalue Problems_, a collection of 52 nonlinear eigenvalue problems in the form of a MATLAB toolbox. (https://github.com/ftisseur/nlevp)\n",
    "\n",
    "Alternatively, perhaps there is some room for improvement when working with sparse matrices. I did not look closely at sparse matrices to understand the set of algorithms available to solve systems of this type. There are however a number of interesting algorithms that have developed from the bioinformatics that permit faster classification, ordering or extreme densification of data and may allow for improved results when dealing with sparse matrices.\n",
    "\n",
    "It is also important to understand how accurate our results need to be. For some systems, dropping half of a properly ordered data set may have minimal impact on the result and would allow for use of additional decomposition methods. Some of this falls into the methods of matrix preconditioning, which is a topic for further review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Python the right approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would argue that python is not really the best language for directly comparing comparing algorithm efficiency. It is fine for the general development of the algorithm but will fail at direct comparison because many of the core underlying algorithms are compiled linked objects. Any code run in the python interpreter will necessarily run slower. If any algorithms are developed, they should be further tested in a compiled language such as *Julia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.eecs.utk.edu/~ielhanan/Papers/JDA2011.pdf\n",
    "* https://www.scirp.org/journal/paperinformation.aspx?paperid=61736\n",
    "* https://www.math.utah.edu/~gustafso/determinants.pdf\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve.html\n",
    "* https://www.netlib.org/lapack/explore-html/d7/d3b/group__double_g_esolve_ga5ee879032a8365897c3ba91e3dc8d512.html\n",
    "* http://www.icl.utk.edu/~mgates3/docs/lapack.html\n",
    "* https://www.netlib.org/lapack/lug/node71.html: Table 3.13\n",
    "* http://www.ma.man.ac.uk/~higham/mctoolbox/\n",
    "* https://people.sc.fsu.edu/~jburkardt/py_src/test_mat/test_mat.html\n",
    "* https://github.com/ftisseur/nlevp\n",
    "* https://www.bioinformaticsalgorithms.org/\n",
    "* https://www.netlib.org/linalg/html_templates/node51.html\n",
    "* https://ieeexplore.ieee.org/document/8742660\n",
    "* https://www.hindawi.com/journals/isrn/2012/127647/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
