\documentclass[12pt]{article}
\setlength{\parskip}{\baselineskip}%
\setlength{\parindent}{0pt}%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[shortlabels]{enumitem}
%\usepackage{tikz}
%\usetikzlibrary{trees}
\usepackage[top=1in, bottom=0.75in, left=0.75in, right=0.75in]{geometry}
\newcommand*{\Scale}[2][4]{\scalebox{#1}{\ensuremath{#2}}}%
\usepackage{listings}

\begin{document}

\title{Math 792 Computation:Cramer's Rule}
\author{by Gary Dalton}
\date{Due February 23, 2021}
\maketitle

\section*{Introduction}
The goal of this project is to solve a system of linear equations using Cramer's rule instead of using the current standard methods.

We will consider linear equations in the form of $Ax=b$, where $A$ is a non-singular $n\times n$ matrix, $b$ is a $n\times 1$ unknown vector, and $b$ is a given $n\times 1$ vector. Cramer's rules states that
\begin{align*}
	x_i = \frac{\det(A_i(b))}{\det(A)}, i=1,2,\cdots,n
\end{align*}
where $A_i(b)$ denotes the matrix $A$ with its ith column replaced by $b$.

The standard method of computing the determinant by recursion of minors is not an efficient computation algorithm. In fact, its complexity is of $O(N!)$, which makes it useless for real world problems. Instead, methods are used to row reduce the matrix to obtain upper and lower triangular matrices and then compute the determinate from those.

\subsection*{Example}
Consider the following system of equations:
\begin{align*}
	a_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 \\
	a_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 \\
	a_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3
\end{align*}
With
\begin{align*}
	&A = \begin{bmatrix}
		a_{1,1} & a_{1,2} & a_{1,3} \\
		a_{2,1} & a_{2,2} & a_{2,3} \\
		a_{3,1} & a_{3,2} & a_{3,3}
	\end{bmatrix}, &
	&x = \begin{bmatrix}x_1 \\	x_2 \\	x_3	\end{bmatrix}, & 
	b = \begin{bmatrix} b_1 \\	b_2 \\	b_3	\end{bmatrix}&
\end{align*}
Then
\begin{align*}
	x_1 &= \frac{\det\begin{bmatrix}
			b_1 & a_{1,2} & a_{1,3} \\
			b_2 & a_{2,2} & a_{2,3} \\
			b_3 & a_{3,2} & a_{3,3}
		\end{bmatrix}
	}{\det(A)}, &
	x_2 = \frac{\det\begin{bmatrix}
			a_{1,1} & b_1 & a_{1,3} \\
			a_{2,1} & b_2 & a_{2,3} \\
			a_{3,1} & b_3 & a_{3,3}
		\end{bmatrix}
	}{\det(A)}, & &
	x_3 = \frac{\det\begin{bmatrix}
			a_{1,1} & a_{1,2} & b_1 \\
			a_{2,1} & a_{2,2} & b_2 \\
			a_{3,1} & a_{3,2} & b_3
		\end{bmatrix}
	}{\det(A)}&
\end{align*}


\section*{Current Approaches}
Current technology with python to solve a system of linear equations uses \textit{scipy.linalg.solve}. This in turn uses routines from LAPACK, "The generic, symmetric, Hermitian and positive definite solutions are obtained via calling ?GESV, ?SYSV, ?HESV, and ?POSV routines of LAPACK respectively."

There are specialized solutions for known special matrices, but we are most interested in the generic solver. From the documentation of ?GESV, we have, 
\begin{quote}
?GESV computes the solution to a real system of linear equations
\begin{align*}
	A * X = B
\end{align*}
where A is an N-by-N matrix and X and B are N-by-NRHS matrices.

The LU decomposition with partial pivoting and row interchanges is
used to factor A as
\begin{align*}
	A = P * L * U
\end{align*}
where P is a permutation matrix, L is unit lower triangular, and U is
upper triangular.  The factored form of A is then used to solve the
system of equations $A * X = B$.
\end{quote}
The complexity of the ?GESV algorithm is indicated as $O(.67N^3)$. This is obtained from table 3.13 in \url{https://www.netlib.org/lapack/lug/node71.html}.

\subsection*{Determinant}
Determinants of triangular matrices are easily calculated as the product of the diagonal entries. Thus $\det(L)$ and $\det(U)$ are easily calculated by $O(n)$ operations. Since P is a permutation matrix, its determinant is trivial to calculate using the method of minors and is of order $O(n)$. $det(P)$ equals either $1$ or $-1$. So that we have:
\begin{align*}
	\det(A) = \det(P) * \det(L) * \det(U)
\end{align*}
This is the method used by both numpy and scipy to calculate a determinant.

\subsection*{Cramer's Rule and LU Decomposition}
Based on the above discussion, Cramer's Rule could be used to solve systems of equations by calculating the various determinants using LU decomposition as an intermediate step. This would give us computation complexity on the order of $O(.67N^3)$ for LU Decomposition $\times$ $O(n)$ for the number of variables to solve. With the result of at best $O(.67N^4)$. This is due to the need to perform LU Decomposition for each $A_i(b)$. If there were a method to reduce this need we might have a competitive algorithm computationally.

I did find one approach that does claim to reduce this complexity to about $O(N^3)$. This is from the Journal of Discrete Algorithms, \url{http://web.eecs.utk.edu/~ielhanan/Papers/JDA2011.pdf} and it uses Chio's condensation method and a few other tricks. I am not certain of this algorithm yet.



\section*{Test Matrices}
Test matrices are an important part of validating algorithms, both for computation speed and accuracy. There are many matrices available for direct download from \url{https://math.nist.gov/MatrixMarket/index.html}. These may be downloaded in MatrixMarket format and then pulled into the test program with the following code snippet.

\begin{lstlisting}[language=Python]
	from scipy import io
	print(io.mminfo('rbs480a.mtx'))
	a = io.mmread('rbs480a.mtx')
	A=  a.todense()
	n = len(A)
\end{lstlisting}

However, many test matrices are generated. Often, these were generated using The Matrix Computation Toolkit for Matlab. A very useful python package to generate a variety of test matrices is in Scipy.sparse. See the code example:

\begin{lstlisting}[language=Python]
# DOCUMENTATION
# https://docs.scipy.org/doc/scipy/reference/sparse.html
# https://docs.scipy.org/doc/scipy/reference/stats.html
	import scipy.sparse as sparse
	import scipy.stats as stats
	
	# sets reproducibility
	np.random.seed(5) 
	# Poisson
	rvs = stats.poisson(18, loc=10).rvs
	# generate sparse 10x10 random matrix with density 0.75
	A = sparse.random(10, 10, density=0.75, data_rvs=rvs)
	rvs = stats.norm(loc=10, scale=20).rvs
	# create sparse 5x5 matrix with density 0.5
	B = sparse.random(5, 5, density=0.50, data_rvs=rvs)
	A = A.toarray()
	B = B.todense()
	A, B
\end{lstlisting}

Is there a difference in using either of these forms, matrix or array? I think that either will work fine but numpy is most suitable for working with arrays for slicing and dicing. So mostly, this work will use the array form of the matrix.

\section*{Solve a Linear System by Cramer's Formula}
Consider the linear systems in the matrix form $Ax =b$.

\subsection*{Create test matrices $A$ and $b$}
\begin{lstlisting}[language=Python]
	import scipy.sparse as sparse
	import scipy.stats as stats
	import scipy.linalg as sla
	# Enter a value of n
	n=50
	# Create A and b
	# sets reproducibility
	np.random.seed(3) 
	# Poisson
	rvs = stats.poisson(18, loc=10).rvs
	# generate sparse 10x10 random matrix with density 0.75
	A = sparse.random(n, n, density=0.75, data_rvs=rvs)
	A = A.toarray()
	b = sparse.random(n, 1, density=0.9, data_rvs=rvs)
	b = b.toarray()
\end{lstlisting}

\subsection*{A Function for Cramer's Rule}
\begin{lstlisting}[language=Python]
def cramer_solve(A, b):
	"""Solve a system of linear equations using 
	Cramer's Rule and LU Decomposition.
	Returns the solution vector."""
	
	# LU Decomposition
	p,l,u = sla.lu(A)
	DA = sla.det(p)* sla.det(l)*sla.det(u)
	
	# Solution storage
	x = np.zeros((n,1))
	x.astype(double)
	
	# Loop to find each solution
	for i in range(len(b)):
		Ai = np.copy(A)
		#         print(np.shape(Ai), np.shape(b))
		Ai[:,i] = b[:,0]
		p,l,u = sla.lu(Ai)
		DAi = sla.det(p)* dia_det(l)*dia_det(u)
		x[i] = DAi / DA
		#         print(x[i])
	return x
	
def dia_det(A):
	det = 1
	for i in range(len(b)):
		det = det *  A[i,i]
	return det
\end{lstlisting}


\section*{Thoughts, Opinions, and Future Directions}
I hold the opinion that attempting a more efficient general system of equations solver is not a good use of time. There may be some interesting and large areas of study that involve sparse matrices or specialized solutions. Potential matrices of this type are available through \textit{NLEVP: A Collection of Nonlinear Eigenvalue Problems}, a collection of 52 nonlinear eigenvalue problems in the form of a MATLAB toolbox. (\url{https://github.com/ftisseur/nlevp})

Alternatively, perhaps there is some room for improvement when working with sparse matrices. I did not look closely at sparse matrices to understand the set of algorithms available to solve systems of this type. There are however a number of interesting algorithms that have developed from the human genome project that permit faster classification, ordering or extreme densification of data and may allow for improved results when dealing with sparse matrices.

It is also important to understand how accurate our results need to be. For some systems, dropping half of a properly ordered data set may have minimal impact on the result and would allow for use of additional decomposition methods. Some of this falls into the methods of matrix preconditioning, which is a topic for further review.

\subsection*{Is Python the right approach?}
I would argue that python is not really the best language for directly comparing comparing algorithm efficiency. It is fine for the general development of the algorithm but will fail at direct comparison because many of the core underlying algorithms are compiled linked objects. Any code run in the python interpreter will necessarily run slower. If any algorithms are developed, they should be further tested in a compiled language such as Julia.


\section*{Resources}
\begin{itemize}
	\item \url{http://web.eecs.utk.edu/~ielhanan/Papers/JDA2011.pdf}
	\item \url{https://www.scirp.org/journal/paperinformation.aspx?paperid=61736}
	\item \url{https://www.math.utah.edu/~gustafso/determinants.pdf}
	\item \url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve.html}
	\item \url{https://www.netlib.org/lapack/explore-html/d7/d3b/group__double_g_esolve_ga5ee879032a8365897c3ba91e3dc8d512.html}
	\item \url{http://www.icl.utk.edu/~mgates3/docs/lapack.html}
	\item \url{https://www.netlib.org/lapack/lug/node71.html} Table 3.13
	\item \url{http://www.ma.man.ac.uk/~higham/mctoolbox/}
	\item \url{https://people.sc.fsu.edu/~jburkardt/py_src/test_mat/test_mat.html}
	\item \url{https://github.com/ftisseur/nlevp}
\end{itemize}

\begin{align*}
\end{align*}

\begin{align*}
\end{align*}

\begin{lstlisting}[language=Python]
\end{lstlisting}

\noindent\rule{\textwidth}{1pt}
{\footnotesize Copyright (C) 2021 Garold Dalton --- Released under GNU General Public License v3.0}

\cleardoublepage

\end{document}
